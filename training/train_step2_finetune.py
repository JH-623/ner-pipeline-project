# -*- coding: utf-8 -*-
import os
import json
import shutil
import torch
import numpy as np
import optuna
import re
import glob
from datasets import load_from_disk
from transformers import (
    AutoTokenizer, AutoModelForTokenClassification,
    TrainingArguments, Trainer,
    DataCollatorForTokenClassification,
    AddedToken
)
from seqeval.metrics import f1_score, precision_score, recall_score


# ------------------- ë²„ì „ ê´€ë¦¬ í•¨ìˆ˜ ------------------- #
def get_latest_versions(base_path):
    """
    ì§€ì •ëœ ê²½ë¡œì—ì„œ ê°€ì¥ ìµœì‹  ë²„ì „ì˜ ì‚¬ì „ê³¼ ëª¨ë¸ ê²½ë¡œë¥¼ ì°¾ì•„ë‚´ê³ ,
    ë‹¤ìŒ ë²„ì „ ë²ˆí˜¸ë¥¼ ê³„ì‚°í•˜ì—¬ ìƒˆë¡œìš´ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    # ì‚¬ì „ íŒŒì¼ ì°¾ê¸° (ì˜ˆ: medical_dict_v7.json)
    dict_pattern = os.path.join(base_path, 'medical_dict_v*.json')
    dict_files = sorted(glob.glob(dict_pattern))
    if not dict_files:
        raise FileNotFoundError(f"ì‚¬ì „ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {dict_pattern}")

    latest_dict_file = dict_files[-1]
    match = re.search(r'_v(\d+)\.json$', latest_dict_file)
    current_version = int(match.group(1)) if match else 0

    next_version = current_version + 1

    # ìƒˆ ëª¨ë¸ ì €ì¥ ê²½ë¡œ ìƒì„±
    output_model_dir = os.path.join(base_path, f'final-korean-ner-model-optimized_v{next_version}')

    print(f"ğŸ”„ ìë™ ë²„ì „ ê°ì§€:")
    print(f"   - ìµœì‹  ì‚¬ì „ íŒŒì¼: {os.path.basename(latest_dict_file)} (ë²„ì „ {current_version})")
    print(f"   - ìƒˆ ëª¨ë¸ ì €ì¥ ê²½ë¡œ: {os.path.basename(output_model_dir)} (ë²„ì „ {next_version})")

    return latest_dict_file, output_model_dir, next_version


# ------------------- ì••ì¶•/í•´ì œ í—¬í¼ í•¨ìˆ˜ ------------------- #
def unzip_model_if_needed(model_path):
    """ì§€ì •ëœ ê²½ë¡œì˜ ëª¨ë¸ íŒŒì¼ ì••ì¶•ì„ í•´ì œí•©ë‹ˆë‹¤."""
    print(f"Checking for zipped models in {model_path}...")
    # optimizer.pt ê°™ì€ ëŒ€ìš©ëŸ‰ íŒŒì¼ì´ ì••ì¶•ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
    zip_files = glob.glob(os.path.join(model_path, '**', '*_archive.zip'), recursive=True)
    if not zip_files:
        print("No zipped models found to unzip.")
        return

    for zip_file in zip_files:
        # ì›ë³¸ íŒŒì¼ ì´ë¦„ì€ '_archive'ë¥¼ ì œì™¸í•œ ì´ë¦„ìœ¼ë¡œ ê°€ì • (ì˜ˆ: optimizer.pt)
        original_filename = os.path.basename(zip_file).replace('_archive.zip', '.pt')  # .pt ì™¸ ë‹¤ë¥¸ í™•ì¥ìë„ ê³ ë ¤ í•„ìš” ì‹œ ìˆ˜ì •
        if 'optimizer' not in original_filename:  # optimizer.pt ì™¸ ë‹¤ë¥¸ íŒŒì¼ì¼ ê²½ìš°ë¥¼ ëŒ€ë¹„
            original_filename = os.path.basename(zip_file).replace('_archive.zip', '.safetensors')

        output_path = os.path.dirname(zip_file)
        original_filepath = os.path.join(output_path, original_filename)

        # ì´ë¯¸ ì›ë³¸ íŒŒì¼ì´ ìˆìœ¼ë©´ ê±´ë„ˆë›°ê¸°
        if os.path.exists(original_filepath):
            print(f"{original_filename} already exists. Skipping unzip.")
            continue

        print(f"Unzipping {zip_file} to {original_filepath}...")
        command = f'zip -s 0 "{zip_file}" --out "{original_filepath}"'
        result = os.system(command)
        if result == 0:
            print("Unzip successful.")
        else:
            raise RuntimeError(f"Error unzipping file: {zip_file}")


def zip_and_cleanup_large_files(model_path):
    """ì§€ì •ëœ ê²½ë¡œì—ì„œ 2GBê°€ ë„˜ëŠ” íŒŒì¼ì„ ì°¾ì•„ ë¶„í•  ì••ì¶•í•˜ê³  ì›ë³¸ì„ ì‚­ì œí•©ë‹ˆë‹¤."""
    print(f"Checking for large files to zip in {model_path}...")
    large_files = []
    # 2GB = 2 * 1024 * 1024 * 1024 bytes
    size_limit_bytes = 2 * 1024 * 1024 * 1024
    for dirpath, _, filenames in os.walk(model_path):
        for filename in filenames:
            filepath = os.path.join(dirpath, filename)
            if os.path.exists(filepath) and not os.path.islink(filepath):
                if os.path.getsize(filepath) > size_limit_bytes:
                    large_files.append(filepath)

    if not large_files:
        print("No large files (>2GB) found to zip.")
        return

    for large_file in large_files:
        print(f"Found large file: {large_file}")
        archive_name = os.path.splitext(large_file)[0] + '_archive.zip'
        print(f"Zipping to {archive_name}...")
        command = f'zip -s 1g "{archive_name}" "{large_file}"'
        result = os.system(command)
        if result == 0:
            print(f"Zip successful. Deleting original file: {large_file}")
            os.remove(large_file)
        else:
            raise RuntimeError(f"Error zipping file: {large_file}")


# ------------------- ì‚¬ìš©ì ì„¤ì • ------------------- #
BASE_DIR = '/home/opc/ner_project/training'  # OCI VM ë‚´ì˜ ì‹¤ì œ ì‘ì—… ê²½ë¡œ
DATASET_DIR = os.path.join(BASE_DIR, 'korean-ner-augmented-v1-dataset')
BASE_MODEL_PATH = os.path.join(BASE_DIR, 'english-ner-model')
MEDICAL_DICT_PATH, OUTPUT_MODEL_DIR, next_version = get_latest_versions(BASE_DIR)

# ------------------- ì „ì—­ ë³€ìˆ˜ ì„¤ì • ------------------- #
tokenizer = None
tokenized_datasets = None
label_names = None
id2label = None
label2id = None
num_labels = None


# ------------------- ë„ë©”ì¸ ë‹¨ì–´/ë ˆì´ë¸” ì²˜ë¦¬ í•¨ìˆ˜ ------------------- #
def load_domain_tokens(json_path):
    with open(json_path, 'r', encoding='utf-8') as f:
        med_dict = json.load(f)
    token_set = set()
    print(f"ğŸ” ì‚¬ì „ì—ì„œ '{', '.join(med_dict.keys())}' ì¹´í…Œê³ ë¦¬ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
    for category, term_dict in med_dict.items():
        for kor, eng in term_dict.items():
            token_set.add(kor.strip())
            token_set.add(eng.strip())
    return list(token_set)


def align_labels_with_tokens(labels, word_ids):
    new_labels = []
    current_word = None
    for word_id in word_ids:
        if word_id != current_word:
            current_word = word_id
            label = -100 if word_id is None else labels[word_id]
            new_labels.append(label)
        elif word_id is None:
            new_labels.append(-100)
        else:
            # ì„œë¸Œì›Œë“œì—ëŠ” -100ì„ í• ë‹¹í•˜ì—¬ ì†ì‹¤ ê³„ì‚°ì—ì„œ ì œì™¸
            new_labels.append(-100)
    return new_labels


def tokenize_and_align_labels(examples):
    tokenized_inputs = tokenizer(examples["tokens"], truncation=True, is_split_into_words=True)
    all_labels = examples["ner_tags"]
    new_labels = []
    for i, labels in enumerate(all_labels):
        word_ids = tokenized_inputs.word_ids(i)
        new_labels.append(align_labels_with_tokens(labels, word_ids))
    tokenized_inputs["labels"] = new_labels
    return tokenized_inputs


def compute_metrics(eval_preds):
    logits, labels = eval_preds
    predictions = np.argmax(logits, axis=-1)
    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]
    true_predictions = [
        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]
        for prediction, label in zip(predictions, labels)
    ]
    return {
        "f1": f1_score(true_labels, true_predictions),
        "precision": precision_score(true_labels, true_predictions),
        "recall": recall_score(true_labels, true_predictions),
    }


# ------------------- Optuna ìµœì í™” ê´€ë ¨ í•¨ìˆ˜ ------------------- #
def model_init():
    model = AutoModelForTokenClassification.from_pretrained(
        BASE_MODEL_PATH,
        id2label=id2label,
        label2id=label2id,
        num_labels=num_labels,
        ignore_mismatched_sizes=True
    )
    model.resize_token_embeddings(len(tokenizer))
    return model


def objective(trial):
    # ì„ì‹œ ì¶œë ¥ ë””ë ‰í„°ë¦¬ ì„¤ì • (ë©”ëª¨ë¦¬ ê´€ë¦¬)
    temp_output_dir = f"./tmp_trial_{trial.number}"

    training_args = TrainingArguments(
        output_dir=temp_output_dir,
        learning_rate=trial.suggest_float("learning_rate", 1e-5, 5e-5, log=True),
        num_train_epochs=trial.suggest_int("num_train_epochs", 5, 10),
        per_device_train_batch_size=trial.suggest_categorical("per_device_train_batch_size", [4, 8]),
        weight_decay=trial.suggest_float("weight_decay", 0.0, 0.1),
        evaluation_strategy="epoch",
        save_strategy="no",
        logging_steps=10,
        disable_tqdm=True,
        report_to=[],
    )

    trainer = Trainer(
        model_init=model_init,
        args=training_args,
        train_dataset=tokenized_datasets["train"],
        eval_dataset=tokenized_datasets["validation"],
        data_collator=DataCollatorForTokenClassification(tokenizer),
        tokenizer=tokenizer,
        compute_metrics=compute_metrics,
    )

    trainer.train()
    eval_result = trainer.evaluate()
    print(f"[Trial {trial.number}] Eval result: {eval_result}")

    # í‰ê°€ í›„ ì„ì‹œ ë””ë ‰í„°ë¦¬ ì •ë¦¬
    shutil.rmtree(temp_output_dir, ignore_errors=True)

    return eval_result.get("eval_f1", 0.0)


# ------------------- í›ˆë ¨ ì‹¤í–‰ë¶€ ------------------- #
if __name__ == "__main__":
    # --- í•™ìŠµ ì „ ë² ì´ìŠ¤ ëª¨ë¸ ì••ì¶• í•´ì œ ---
    print("\nğŸš€ 0. ë² ì´ìŠ¤ ëª¨ë¸ ì••ì¶• í•´ì œ í™•ì¸...")
    unzip_model_if_needed(BASE_MODEL_PATH)

    print("\nğŸš€ 1. ë°ì´í„° ë° í† í¬ë‚˜ì´ì € ì¤€ë¹„...")
    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_PATH)
    custom_tokens = load_domain_tokens(MEDICAL_DICT_PATH)
    added_tokens = [AddedToken(t, single_word=True) for t in custom_tokens]
    tokenizer.add_tokens(added_tokens)
    print(f"âœ… ì¶”ê°€ëœ ë„ë©”ì¸ í† í° ìˆ˜: {len(added_tokens)}")

    raw_datasets = load_from_disk(DATASET_DIR)
    tokenized_datasets = raw_datasets.map(
        tokenize_and_align_labels,
        batched=True,
        remove_columns=raw_datasets["train"].column_names,
    )

    label_names = raw_datasets['train'].features['ner_tags'].feature.names
    id2label = {i: label for i, label in enumerate(label_names)}
    label2id = {label: i for i, label in id2label.items()}
    num_labels = len(label_names)

    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸ’» í›ˆë ¨ ì¥ì¹˜: {device.upper()}")

    print("\nğŸš€ 2. Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ ì‹œì‘ (5 trials)...")
    study = optuna.create_study(direction="maximize")
    study.optimize(objective, n_trials=5)

    print(f"\nğŸ‰ íƒìƒ‰ ì™„ë£Œ! ìµœì  F1 ì ìˆ˜: {study.best_value:.4f}")
    print("ğŸ“ˆ ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°:")
    for key, value in study.best_params.items():
        print(f"   - {key}: {value}")

    print("\nğŸš€ 3. ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ ìµœì¢… ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")

    best_params = study.best_params

    final_training_args = TrainingArguments(
        output_dir=OUTPUT_MODEL_DIR,
        eval_strategy="epoch",
        save_strategy="epoch",
        logging_strategy="epoch",
        learning_rate=best_params["learning_rate"],
        per_device_train_batch_size=best_params["per_device_train_batch_size"],
        num_train_epochs=best_params["num_train_epochs"],
        weight_decay=best_params["weight_decay"],
        save_total_limit=2,
        load_best_model_at_end=True,
        metric_for_best_model="eval_f1",
        greater_is_better=True,
        logging_dir="./logs",
        report_to="none",
        seed=42
    )
    data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)

    final_trainer = Trainer(
        model=model_init(),
        args=final_training_args,
        train_dataset=tokenized_datasets["train"],
        eval_dataset=tokenized_datasets["validation"],
        tokenizer=tokenizer,
        data_collator=data_collator,
        compute_metrics=compute_metrics
    )

    final_trainer.train()

    print("\nğŸ’¾ ìµœì¢… ëª¨ë¸ ì €ì¥ ì¤‘...")
    final_trainer.save_model(OUTPUT_MODEL_DIR)
    tokenizer.save_pretrained(OUTPUT_MODEL_DIR)
    print(f"\nğŸ‰ ìµœì í™”ëœ í•œêµ­ì–´ NER ëª¨ë¸ ì €ì¥ ì™„ë£Œ: '{OUTPUT_MODEL_DIR}'")

    # --- í•™ìŠµ í›„ ìƒˆ ëª¨ë¸ ì••ì¶• ë° ì •ë¦¬ ---
    print("\nğŸš€ 4. ìƒˆë¡œ ìƒì„±ëœ ëŒ€ìš©ëŸ‰ ëª¨ë¸ íŒŒì¼ ì••ì¶• ë° ì •ë¦¬...")
    zip_and_cleanup_large_files(OUTPUT_MODEL_DIR)

    print("\nğŸš€ 5. ìƒˆ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ë° ìë™ ë°°í¬ ì‹œì‘...")

    # 5-1. ë°©ê¸ˆ í›ˆë ¨í•œ ìƒˆ ëª¨ë¸ì˜ F1 ì ìˆ˜ ê°€ì ¸ì˜¤ê¸°
    eval_results = final_trainer.evaluate()
    new_f1_score = eval_results.get("eval_f1", 0.0)
    print(f" - ìƒˆ ëª¨ë¸ F1 ì ìˆ˜: {new_f1_score:.4f}")

    # 5-2. í˜„ì¬ ì„œë¹„ìŠ¤ ì¤‘ì¸ ëª¨ë¸ì˜ ì„±ëŠ¥ ì§€í‘œ ë¡œë“œ
    production_metrics_file = os.path.join(BASE_DIR, 'production_metrics.json')
    try:
        with open(production_metrics_file, 'r') as f:
            prod_metrics = json.load(f)
        prod_f1_score = prod_metrics.get("f1", 0.0)
    except FileNotFoundError:
        prod_f1_score = 0.0  # íŒŒì¼ì´ ì—†ìœ¼ë©´ 0ì ìœ¼ë¡œ ê°„ì£¼í•˜ì—¬ í•­ìƒ ì—…ë°ì´íŠ¸

    print(f" - í˜„ì¬ ëª¨ë¸ F1 ì ìˆ˜: {prod_f1_score:.4f}")

    # 5-3. ì„±ëŠ¥ ë¹„êµ í›„ ìë™ ë°°í¬ ê²°ì •
    if new_f1_score > prod_f1_score:
        print("\nâœ… ì„±ëŠ¥ í–¥ìƒ! ìƒˆ ëª¨ë¸ì„ Gitì— í‘¸ì‹œí•˜ì—¬ ìë™ ë°°í¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")

        # ìƒˆ ì„±ëŠ¥ ì§€í‘œë¥¼ íŒŒì¼ì— ì €ì¥ (ë‹¤ìŒ ë¹„êµë¥¼ ìœ„í•´)
        with open(production_metrics_file, 'w') as f:
            json.dump({"f1": new_f1_score}, f)

        # Git ëª…ë ¹ì–´ ì‹¤í–‰
        try:
            os.system('git config --global user.name "AutoTrain Bot"')
            os.system('git config --global user.email "bot@example.com"')
            os.system('git add .')
            commit_message = f"Auto-train: Update model to v{next_version} with F1 score {new_f1_score:.4f}"
            os.system(f'git commit -m "{commit_message}"')
            os.system('git push origin main')
            print("âœ… Git push ì™„ë£Œ! CD íŒŒì´í”„ë¼ì¸ì´ ìƒˆ ëª¨ë¸ì„ ë°°í¬í•©ë‹ˆë‹¤.")
        except Exception as e:
            print(f"âŒ Git push ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    else:
        print("\nâŒ ì„±ëŠ¥ì´ í–¥ìƒë˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ í˜„ì¬ ëª¨ë¸ì„ ìœ ì§€í•©ë‹ˆë‹¤.")